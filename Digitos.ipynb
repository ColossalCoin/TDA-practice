{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "058219c4-26e1-4e8b-a03d-d01405b2a2a6",
   "metadata": {},
   "source": [
    "# Clasificador de dífitos manuscritos\n",
    "En este ejercicio utilizaremos `giotto-tda` para realizar un análisis topológico de datos sobre el conjunto de datos MNIST, con la finalidad de entrenar un algortimo clasificador. Este ejemplo está basado en el clasificador de dígitos manuscritos de que se encuentra en la página oficial de [Giotto-tda](https://giotto-ai.github.io/gtda-docs/latest/notebooks/MNIST_classification.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9ec993-7474-4335-a515-a05629ea82a0",
   "metadata": {},
   "source": [
    "## Carga de los datos MNIST\n",
    "Comenzamos cargando el conjunto de datos MNIST utilizando la función `fetch_openml` del módulo `sklearn.datasets`. Observemos que el conjunto cuenta con 70,000 imágenes de 784 pixeles cada una."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d563d2a5-1402-4c90-85c8-5cf4b271f292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\miniconda3\\envs\\TDA-practices\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Returning pandas objects requires pandas to be installed. Alternatively, explicitly set `as_frame=False` and `parser='liac-arff'`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniconda3\\envs\\TDA-practices\\Lib\\site-packages\\sklearn\\utils\\__init__.py:1193\u001b[0m, in \u001b[0;36mcheck_pandas_support\u001b[1;34m(caller_name)\u001b[0m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1193\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m   1195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniconda3\\envs\\TDA-practices\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1043\u001b[0m, in \u001b[0;36mfetch_openml\u001b[1;34m(name, version, data_id, data_home, target_column, cache, return_X_y, as_frame, n_retries, delay, parser, read_csv_kwargs)\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1043\u001b[0m     \u001b[43mcheck_pandas_support\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m`fetch_openml`\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\TDA-practices\\Lib\\site-packages\\sklearn\\utils\\__init__.py:1197\u001b[0m, in \u001b[0;36mcheck_pandas_support\u001b[1;34m(caller_name)\u001b[0m\n\u001b[0;32m   1196\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1197\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m requires pandas.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(caller_name)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: `fetch_openml` requires pandas.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_openml\n\u001b[1;32m----> 3\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_openml\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmnist_784\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_X_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX shape:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, y shape:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\TDA-practices\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\TDA-practices\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1051\u001b[0m, in \u001b[0;36mfetch_openml\u001b[1;34m(name, version, data_id, data_home, target_column, cache, return_X_y, as_frame, n_retries, delay, parser, read_csv_kwargs)\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m as_frame:\n\u001b[0;32m   1046\u001b[0m     err_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1047\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning pandas objects requires pandas to be installed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1048\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlternatively, explicitly set `as_frame=False` and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1049\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`parser=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliac-arff\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1050\u001b[0m     )\n\u001b[1;32m-> 1051\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(err_msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1053\u001b[0m     err_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1054\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `parser=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparser_\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m` requires pandas to be installed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1055\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlternatively, explicitly set `parser=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliac-arff\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1056\u001b[0m     )\n",
      "\u001b[1;31mImportError\u001b[0m: Returning pandas objects requires pandas to be installed. Alternatively, explicitly set `as_frame=False` and `parser='liac-arff'`."
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True)\n",
    "\n",
    "print(f'X shape:{X.shape}, y shape:{y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b73a7a1-90be-455a-924f-880d2deaf63d",
   "metadata": {},
   "source": [
    "Dado que las imágenes han sido \"aplanadas\" en un arreglo unidimensional, redimensionaremos el arreglo en un vector de $28\\times 28$ y visualizaremos algunos de los dígitos mediante la función `plot_heatmap` de `gtda.plotting`. A continuación se muestran algunas de las imágenes del conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f9b029-9698-4dd9-910f-2fc92e9551ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gtda.plotting import plot_heatmap\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "digits_idx = [np.flatnonzero(y == chr(digit))[0] for digit in range(ord('0'), ord('9'))]\n",
    "digits = [np.asarray(X.iloc[digit_idx]).reshape(28, 28) for digit_idx in digits_idx]\n",
    "digit_plots = [plot_heatmap(digit) for digit in digits]\n",
    "\n",
    "fig = make_subplots(3, 3)\n",
    "fig.update_layout(width=800, height=600)\n",
    "\n",
    "i = 0\n",
    "for row in range(1, 4):\n",
    "    for col in range(1, 4):\n",
    "        if i != 0:\n",
    "            fig['layout']['yaxis' + str(i)]['autorange'] = 'reversed'\n",
    "        else:\n",
    "            fig['layout']['yaxis']['autorange'] = 'reversed'\n",
    "            \n",
    "        fig.add_trace(digit_plots[i]['data'][0], row=row, col=col)\n",
    "        i += 1\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee02e14d-d7dc-4331-8686-df750d9d4369",
   "metadata": {},
   "source": [
    "## Separamos el conjunto de datos\n",
    "Para este ejemplo trabajaremos con un subconjunto de datos, de igual forma que en el ejercicio original de Giotto-tda. En este caso consideraremos una muestra de 70 elementos, donde separaremos dicho subconjunto en datos de entrenamiento y validación con una relación 85-15, es decir, 60 datos de entrenamiento y 10 de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d15d4d-07b7-4507-922f-d6193912b916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_size, test_size = 60, 10\n",
    "\n",
    "X = np.asarray(X).reshape((-1, 28, 28))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size, test_size=test_size, stratify=y, random_state=666)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd426f6-18b7-43c7-8df0-223bc891632e",
   "metadata": {},
   "source": [
    "## Características topológicas\n",
    "A diferencia del cálculo de las características topológicas de un conjunto de datos como el visto en el notebook de figuras 3D, encontrar características topológicas en una imagen no es un procedimiento tan directo. Dado que una imagen generalmente está representada por píxeles, es conveniente utilizar complejos cúbicos en ligar de complejos simpliciales. Como ejemplo del procedimiento a seguir, realizaremos el mismo sobre un único dígito, a saber, el 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9686a9b2-29fc-4dc6-b152-b2257c66175b",
   "metadata": {},
   "outputs": [],
   "source": [
    "im8_idx = np.flatnonzero(y_train == '8')[0]\n",
    "\n",
    "# En este caso necesitamos el formato (n_samples, n_pixels_x, n_pixels_y)\n",
    "im8 = X_train[im8_idx][None, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f72552a-4cad-4fa9-82db-ebcc428163bc",
   "metadata": {},
   "source": [
    "### Binarizado de la imagen\n",
    "Las filtraciones mediante complejos cúbicos en `giotto-tda` se aplican únicamente a *imágenes binarias*, las cuales consisten en solo píxeles en blanco y negro. Podemos convertir imágenes en escala de grises a imágenes binarias mediante la función `Binarizer` del módulo `gtda.images`, considerando un umbral adecuado en cada píxel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee94b148-4139-42f6-97f4-1bb9e56ed467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtda.images import Binarizer\n",
    "\n",
    "# El umbral elegido en este caso es de 0.4\n",
    "binarizer = Binarizer(threshold=0.4)\n",
    "im8_binarized = binarizer.fit_transform(im8)\n",
    "\n",
    "binarizer.plot(im8_binarized, \n",
    "               plotly_params={'layout':{'width':800, 'height':600}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044c5026-5ac3-43f7-9b60-7254c8be3fff",
   "metadata": {},
   "source": [
    "### Filtrado de la imagen\n",
    "Ahora que hemos binarizado nuestra imagen $\\mathcal B$, podemos comenzar con el filtrado de la misma, podemos encontrar las distintas técnicas de filtrado disponibles en `giotto-tda` en la [documentación](https://giotto-ai.github.io/gtda-docs/latest/modules/images.html#filtrations) oficial. Para este ejemplo utilizaremos el *filtrado radial* $\\mathcal R$, el cual consiste en asignar a cada píxel $p$ su distancia al \"centro\" $c$ de la imagen, de tal forma que\n",
    "$$\n",
    "\\mathcal R(p)=\n",
    "\\begin{cases}\n",
    "\\|c-p\\|_2          &\\text{si}\\quad\\mathcal B(p)=1\\\\\n",
    "\\mathcal R_\\infty  &\\text{si}\\quad\\mathcal B(p)=0\n",
    "\\end{cases}\n",
    "$$\n",
    "donde $\\mathcal R_\\infty$ es la distancia del píxel más alejado de $c$. Con la finalidad de reproducir el filtrado realizado en el [artículo](https://arxiv.org/abs/1910.08345) de MNIST, consideramos $c=(20,6)$. Para realizar el filtrado radial utilizaremos la función `RadialFiltration` de `gtda.images`.\n",
    "\n",
    "Podemos interpretar el gráfico resultante como:\n",
    "* Azul: Cercano a $c$.\n",
    "* Rojo. Lejano a $c$.\n",
    "\n",
    "De esta forma, hemos regresado el gráfico a una escala de grises, pero esta vez la escala tiene una interpretación geométrica clara. Los valores de estos píxeles pueden utilizarse para crear una filtración mediante complejos cúbicos $\\{K_i\\}_{i\\in\\text{Im}(I)}$, donde $K_i$ contiene a los píxeles con valores menores al $i$-ésimo valor más pequeño en términos de intensidad en la escala de grises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82da379-57f4-4c9b-91b7-dbf15f9476f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtda.images import RadialFiltration\n",
    "\n",
    "# RadialFiltration toma como argumento un centro de tipo array\n",
    "radial_filtration = RadialFiltration(center=np.array([20, 6]))\n",
    "im8_filtration = radial_filtration.fit_transform(im8_binarized)\n",
    "\n",
    "radial_filtration.plot(im8_filtration, colorscale='jet',\n",
    "                      plotly_params={'layout':{'width':800, 'height':600}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca54aea-dd3a-4f51-9d3b-7c8d5a4a1942",
   "metadata": {},
   "source": [
    "## Diagrama de persistencia\n",
    "Como se ha mencionado anteriormente, esta filtración se realizará mediante complejos cúbicos, para lo cual utilizaremos la función `CubicalPersistence` del módulo `gtda.homology`. En el gráfico de persistencia (idealmente) no deberíamos observar a cerca de\n",
    "* H_0: un único punto.\n",
    "* H_1: dos puntos notablemente alejados de la diagonal.\n",
    "\n",
    "En este caso queda claro que el gráfico de persistencia real se aemeja bastante al esperado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95db2011-36af-42f1-9686-f2638e5eb0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtda.homology import CubicalPersistence\n",
    "\n",
    "cubical_persistence = CubicalPersistence()\n",
    "im8_cubical = cubical_persistence.fit_transform(im8_filtration)\n",
    "\n",
    "cubical_persistence.plot(im8_cubical, \n",
    "                         plotly_params={'layout':{'title':'Gráfico de persistencia de un 8'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a866eea-161c-43d6-9bde-f0253a571af0",
   "metadata": {},
   "source": [
    "Un punto a destacar es la escala del diagrama anterior, el cual va de 0 a 30 en ambos ejes. Resulta conveniente reescalar los diagramas, tarea que puede ser realizada por la función `Scaler` del módulo `gtda.diagrams`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590a74a9-b1ed-4b1e-b086-c702ac00ca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtda.diagrams import Scaler\n",
    "\n",
    "scaler = Scaler()\n",
    "im8_scaled = scaler.fit_transform(im8_cubical)\n",
    "\n",
    "scaler.plot(im8_scaled, \n",
    "            plotly_params={'layout':{'title':'Diagrama de persistencia de un 8 (reescalado)'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c7990f-7a50-49dc-808d-4c9d82882fe3",
   "metadata": {},
   "source": [
    "## Kernel gaussiano\n",
    "Una vez hemos obtenido el diagrama de persistencia deseado, es momento de vectorizar el mismo para extraer la información conveniente. En este caso utlizaremos un método de kernel gaussianos para realizar dicha vectorización. La técnica de kernel gaussiano (al igual que otras técnicas de kernel) consiste en aplicar convoluciones a nuestro diagrama de persistencia, y simetrizar a lo largo de la diagonal. El proceso anteriormente descrito puede ser realizado mediante la función `HeatKernel` del módulo `gtda.diagrams`, la cual requiere especificar los parámetros\n",
    "* sigma(`float`, 0.1 por defecto): La desciación estándar del kernel gaussiano.\n",
    "* n_bins(`int`, 100 por defecto): El número de valores de parámetros de filtración para muestrear durante el ajuste del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f7502d-cfa3-4b79-a61d-31dcf7629dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtda.diagrams import HeatKernel\n",
    "\n",
    "heat = HeatKernel(sigma=0.15, n_bins=60)\n",
    "im8_heat = heat.fit_transform(im8_scaled)\n",
    "\n",
    "heat.plot(im8_heat, homology_dimension_idx=0, colorscale='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b0d6f4-a82b-4950-812c-cfa39cbc23a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat.plot(im8_heat, homology_dimension_idx=1, colorscale='jet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbe3867-91e5-41d6-8156-c942c5c0c474",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "Ahora que tenemos desarrollada una metodología para extraer las características topológicas deseadas, podemos diseñar el pipeline para analizar el conjunto de datos previamente definidos. Comenzaremos creando el pipeline basado en el ejemplo anterior, para posteriormente generalizarlo más tarde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e07c86e-d85d-47a9-aecb-3d499342a47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from gtda.diagrams import Amplitude\n",
    "\n",
    "steps = [\n",
    "    ('binarizer', Binarizer(threshold=0.4)),\n",
    "    ('filtration', RadialFiltration(center=np.array([20, 6]))),\n",
    "    ('diagram', CubicalPersistence()),\n",
    "    ('rescaling', Scaler()),\n",
    "    ('amplitude', Amplitude(metric='heat', metric_params={'sigma':0.15, 'n_bins':60}))\n",
    "]\n",
    "\n",
    "heat_pipline = Pipeline(steps)\n",
    "im8_pipeline = heat_pipline.fit_transform(im8)\n",
    "im8_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f366ef-6e48-4d67-9120-a976f5ad1aca",
   "metadata": {},
   "source": [
    "## Procesando el conjunto de datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
